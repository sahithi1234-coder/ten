**Question:** Use Locust to simulate multiple users calling the model inference endpoint.
•	**Prerequisites:**
•	locust installed
•	Running inference API
•	**Solution Guide:**
•	# Save as locustfile.py
•	from locust import HttpUser, task
•	class MLTest(HttpUser):
•	    @task
•	    def predict(self):
•	        self.client.post("/predict", json={"features": [5.1, 3.5, 1.4, 0.2]})
•	# Run test
•	locust -f locustfile.py --host=http://localhost:5000
